---
title: "Statistical Inference Using R"
author: "Paramjot Singh"
date: 2018-03-22T03:40:34-05:00
draft: FALSE
tags: ["R"]
categories: ["Fundamentals"]
output:
  blogdown::html_page:
    toc: true
---


<div id="TOC">
<ul>
<li><a href="#everything-varies">Everything Varies</a></li>
<li><a href="#mean---one-measure-of-central-tendency">Mean - One Measure of Central Tendency</a></li>
<li><a href="#sample-vs-population">Sample vs Population</a></li>
<li><a href="#estimating-a-population-parameter-from-a-sample-quantity">Estimating a Population Parameter from a Sample Quantity</a></li>
<li><a href="#variance---a-measure-of-spread">Variance - A Measure of Spread</a></li>
<li><a href="#what-is-the-variance-in-estimate-of-mean">What is the Variance in Estimate of Mean</a></li>
<li><a href="#central-limit-theorem">Central Limit Theorem</a></li>
<li><a href="#key-facts-about-normal-distribution">Key Facts about Normal Distribution</a></li>
<li><a href="#confidence-intervals-for-the-estimate-of-mean">Confidence Intervals for the Estimate of Mean</a></li>
<li><a href="#calculation-of-confidence-intervals-using-r-functions">Calculation of Confidence Intervals using R Functions</a></li>
<li><a href="#hypothesis-testing---a-systematic-approach-to-compare-sample-data">Hypothesis Testing - A Systematic Approach to Compare Sample Data</a></li>
<li><a href="#potholes-in-hypothesis-testing">Potholes in Hypothesis Testing</a></li>
<li><a href="#what-is-power">What is Power?</a></li>
<li><a href="#small-sample">Small Sample?</a></li>
<li><a href="#problems">Problems</a></li>
<li><a href="#what-if-i-want-to-study-a-test-statistic-other-than-mean">What if I Want to Study a Test Statistic Other than Mean?</a></li>
<li><a href="#permutation-testing---a-different-way-of-hypothesis-testing">Permutation Testing - A Different Way of Hypothesis Testing</a></li>
</ul>
</div>

<p>Imagine you were in the market for a new car. You care about running cost of the car and thus one of the buying criteria you have in mind is better fuel economy. One of your friend suggests to buy a 4-cylinder car instead of 6 or 8 cylinders since larger engine size usually translates to worse fuel economy. You are a data scientist so you just don’t take his word but want to look at some concrete data before you narrow down your search to 4-cylinder vehicles. You find this <code>mpg</code> dataset in one of the R packages, <code>ggplot2</code> and start to look at it to answer your question:</p>
<blockquote>
<p>Do 4-cylinder cars have better fuel economy than 6-cylinder cars?</p>
</blockquote>
<p>This is a type of question that statistical inference will help us answer. In this post, we will learn the fundamental concepts related to inference. As usual, we will keep the focus tight on the minimum set of tools needed to start applying the concepts to data at hand. We will add more tools as we start to play with different types of data.</p>
<div id="everything-varies" class="section level3">
<h3>Everything Varies</h3>
<p>Variation is inherent to all phenomenon and processes. Otherwise our job is done. Our objective is to understand the variation in data so we can make an informed decision. So we want to ‘quantify’ the variation in our data. Just looking at the raw data is not going to cut it. Let’s try:</p>
<pre class="r white"><code>library(tidyverse)
hwy_4 &lt;- mpg %&gt;% 
    filter(cyl == 4) %&gt;% 
    select(hwy)
hwy_6 &lt;- mpg %&gt;% 
    filter(cyl == 6) %&gt;% 
    select(hwy)
hwy_4
#&gt; # A tibble: 81 x 1
#&gt;      hwy
#&gt;    &lt;int&gt;
#&gt;  1    29
#&gt;  2    29
#&gt;  3    31
#&gt;  4    30
#&gt;  5    26
#&gt;  6    25
#&gt;  7    28
#&gt;  8    27
#&gt;  9    27
#&gt; 10    30
#&gt; # ... with 71 more rows</code></pre>
<pre class="r white"><code>hwy_6
#&gt; # A tibble: 79 x 1
#&gt;      hwy
#&gt;    &lt;int&gt;
#&gt;  1    26
#&gt;  2    26
#&gt;  3    27
#&gt;  4    25
#&gt;  5    25
#&gt;  6    25
#&gt;  7    25
#&gt;  8    24
#&gt;  9    25
#&gt; 10    26
#&gt; # ... with 69 more rows</code></pre>
<p>It is not a bad idea to look at the raw data but it is difficult to conclude anything. Surprisingly, the fuel economy numbers are rounded to 2 significant figures (and thus of type <em>integer</em>). Generally, mpg numbers are provided with 3 decimal places. It appears that 4-cylinder vehicles have slightly better fuel economy but there is some overlap too. Moreover, our brain will start to complain if we stare at 80 data points for each set for too long. And sometimes we may have to work with many more observations. One tool to ease out that pain is plots. Let’s look at the histogram of each set:</p>
<pre class="r white"><code>library(themeSimple)
ggplot(hwy_4, aes(hwy)) +
    histogram(binwidth = 3) + 
    xlim(15, 45) +
    theme_simple()</code></pre>
<p><img src="/post/statistical-inference-using-R_files/figure-html/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r white"><code>
ggplot(hwy_6, aes(hwy)) +
    histogram(binwidth = 3) +
    xlim(15, 45) +
    theme_simple()</code></pre>
<p><img src="/post/statistical-inference-using-R_files/figure-html/unnamed-chunk-2-2.png" width="672" style="display: block; margin: auto;" /> I kept the x-axis scale same in both plots so we can compare the two easily. It is apparent that the mean of 4-cylinder vehicles is centered aroung 30 mpg (miles per gallon) while it is around 25 mpg for 6-cylinder vehicles. So should you conclude that 4-cylinder cars are better? Well, let’s wait until we get some quantifiable differences.</p>
</div>
<div id="mean---one-measure-of-central-tendency" class="section level3">
<h3>Mean - One Measure of Central Tendency</h3>
<p>To quantify the difference, one measure we can consider is <em>mean</em>, which is a measure of central tendency of the data:</p>
<pre class="r white"><code>mpg %&gt;% 
    group_by(cyl) %&gt;%
    filter(cyl == 4 | cyl == 6) %&gt;%
    summarize(mean_hwy = mean(hwy))
#&gt; # A tibble: 2 x 2
#&gt;     cyl mean_hwy
#&gt;   &lt;int&gt;    &lt;dbl&gt;
#&gt; 1     4     28.8
#&gt; 2     6     22.8</code></pre>
<p>So the mean fuel economy of 4-cylinder cars is greater than 6-cylinder cars by 6 mpg! That’s quite a bit. And now we have quantified the difference. Can we conclude now that 4-cylinder cars are better than 6-cylinders? Well not so fast!</p>
</div>
<div id="sample-vs-population" class="section level3">
<h3>Sample vs Population</h3>
<p>One thing is clear that your friend is not going to pick up one of the cars used to generate this data. For one, the latest model (2008) in the data set is 10 years old. The data we have with us is called <em>sample</em> and the mean we have calculated is called <em>sample mean</em>. This sample comes from <em>population</em> that in this case consists of all the 4 and 6 cylinder cars manufactured in US from year 1999 to 2008. What we really want to know is <em>population mean</em>. But there is no way to exactly know the population mean (unless you are ready to measure mpg for all the cars, which is a costly proposition!). The only option we have is to <em>estimate</em> population mean from sample mean.</p>
</div>
<div id="estimating-a-population-parameter-from-a-sample-quantity" class="section level3">
<h3>Estimating a Population Parameter from a Sample Quantity</h3>
<p><strong>How do we estimate population mean from sample mean?</strong></p>
<p>The answer is quite simple here.</p>
<blockquote>
<p>Sample mean is an <em>unbiased estimator</em> of population mean.</p>
</blockquote>
<p>Sample mean is an <em>unbiased</em> estimator of population mean so we don’t have to worry too much about the estimate here. What we need to answer is <em>how confident</em> are we in our estimate? It is likely that if we collect another sample, the mean of that sample is not going to be exactly same as the first. This is because since the individual observations are <em>random numbers</em>, anything that we calculate from those will also be a random number. To understand the variability in mean, we need to know a bit about <em>variance</em>.</p>
</div>
<div id="variance---a-measure-of-spread" class="section level3">
<h3>Variance - A Measure of Spread</h3>
<p>While mean gives you central tendency of a population, <em>variance</em> represents the spread or distribution of observations around the mean. We typically think of variance in terms of <em>standard deviation</em> which is just the square root of variance. This is because the units of standard deviation matches with the data we are analyzing. So in short, a data with standard deviation of 5 will be more spread out compared to a data with standard deviation of 1. Let’s look at the histogram of these two sets:</p>
<pre class="r white"><code>low_var &lt;- rnorm(1000)
high_var &lt;- rnorm(1000, mean = 0, sd = 5)
data &lt;- tibble(id = rep(c(&quot;low&quot;, &quot;high&quot;), each = 1000), 
               obs = c(low_var, high_var))
ggplot(data, aes(x = obs)) +
    histogram(data = filter(data, id == &quot;high&quot;), 
              fill = &#39;darkorange&#39;, 
              alpha = 0.8) +
    histogram(data = filter(data, id == &quot;low&quot;), 
              alpha = 0.8) +
    theme_simple()</code></pre>
<p><img src="/post/statistical-inference-using-R_files/figure-html/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="what-is-the-variance-in-estimate-of-mean" class="section level3">
<h3>What is the Variance in Estimate of Mean</h3>
<p>Now that we know what variance is, we need to find what is the variance in our estimate of mean. It turns out that the variance in the estimate of mean is simply the variance of the sample divided by the number of observations in the sample. It follows then that the standard deviation of estimate of our mean (also known as the <em>standard error of mean</em>) is the standard deviation of the sample divided by the square root of the number of observations. Thus, as our sample size increases, the standard error of mean decreases increasing our confidence in the estimate of mean.</p>
<blockquote>
<p><em>Standard error of mean is equal to standard deviation of the sample divided by the square root of the number of observations</em></p>
</blockquote>
<p>Let’s calculate <em>SE of mean</em> of our two samples:</p>
<pre class="r white"><code>semean_hwy_4 &lt;- signif(sd(pull(hwy_4, hwy)) / sqrt(length(pull(hwy_4, hwy))), 3)
semean_hwy_4
#&gt; [1] 0.502</code></pre>
<pre class="r white"><code>semean_hwy_6 &lt;- signif(sd(pull(hwy_6, hwy)) / sqrt(length(pull(hwy_6, hwy))), 3)
semean_hwy_6
#&gt; [1] 0.415</code></pre>
<p>This is interesting. From a single sample of data, we know the estimate of population mean and the variance in this estimate. Is it possible to know more about what this population of sample means look like. In other words, if I could not take just one sample, but 10, 100 or thousands of samples, calculate mean of each sample and plot a histogram, what would the distribution of those means look like? The answer comes from the mighty <em>Central Limit Theorem</em>.</p>
</div>
<div id="central-limit-theorem" class="section level3">
<h3>Central Limit Theorem</h3>
<p>Central Limit Theorem (CLT) says that regrdless of what the distribution of individual observations of a certain population looks like, the distribution of sample means gets closer and closer to <em>normal distribution</em> as the number of observations increase.</p>
<blockquote>
<p><em>Distribution of averages of a random variable samples gets closer and closer to normal distribution as the sample size increases.</em></p>
</blockquote>
</div>
<div id="key-facts-about-normal-distribution" class="section level3">
<h3>Key Facts about Normal Distribution</h3>
<p>Now that we know that the distribution of averages follows normal distribution, it will help to know a little bit about this normal distribution. Normal distribution has a <em>bell shape</em> and is also referred to as <em>Gaussian Distribution</em>. Due to the bell shape, more observations are concentrated at the center (mean) and the density decreases as we move away from the center in either direction.</p>
<ul>
<li>A normal distrubution with a mean of 0 and standard deviation of 1 is known as <em>standard normal distribution</em>.</li>
<li>68%, 95% and 99% of the normal density lies within approximately 1, 2 and 3 standard deviations from the mean.</li>
<li>-1.96, -1.645, 1.645, 1.96 are the 2.5th, 5th, 95th and 97.5th percentiles of the standard normal distribution.</li>
</ul>
<p>These facts allow us to build confidence intervals for any estimate that follows a normal distribution.</p>
</div>
<div id="confidence-intervals-for-the-estimate-of-mean" class="section level3">
<h3>Confidence Intervals for the Estimate of Mean</h3>
<p>Now we have the knowledge to create confidence intervals for our estimate of mean. For example, since the mean follow normal distribution (per CLT), 95% of the means will lie within <em>+/- 2 x SE</em>:</p>
<pre class="r white"><code>CI_4 &lt;- mean(pull(hwy_4)) + c(-2, 2) * semean_hwy_4
signif(CI_4, 3)
#&gt; [1] 27.8 29.8</code></pre>
<pre class="r white"><code>CI_6 &lt;- mean(pull(hwy_6)) + c(-2, 2) * semean_hwy_6
signif(CI_6, 3)
#&gt; [1] 22.0 23.7</code></pre>
<p><strong>What does these confidence intervals mean?</strong></p>
<p>The above interval means that we are 95% confident that the population lies in this interval. Another way to think is that if we take 100 4-cylinder samples, and construct confidence intervals using the above calculated values, approximately 95 of those intervals will contain the population mean.</p>
</div>
<div id="calculation-of-confidence-intervals-using-r-functions" class="section level3">
<h3>Calculation of Confidence Intervals using R Functions</h3>
<p>We can directly use R functions (<code>pnorm</code> and <code>qnorm</code>) to calculate quantities for normal distributions.</p>
<p><strong>The mean SAT score is 1083 with a standard deviation of 194. What is the probability that a randomly drawn student from this population has a score of 800 or less?</strong></p>
<p>Notice here that we are directly given the population parameters. We don’t have a single sample. So assuming this population is normally distributed, we are asked to find the area bounded by the curve representing this distribution, x-axis and the left of the vertical line drawn at 800 x-axis point. This can be computed by:</p>
<pre class="r white"><code>pnorm(800, 1083, 194)
#&gt; [1] 0.07231519</code></pre>
<p>So we can say that there is less than 8% chance of randomly picking a student with a SAT score of 800 or less from this population.</p>
<p><strong>What is the probability that a randomly drawn student from this population has a score of 1150 or more?</strong></p>
<p>Now we need the area to the <em>right</em> of vertical line drawn at 1150. So we will use the argument <strong>lower.tail = FALSE</strong> to answer this question:</p>
<pre class="r white"><code>pnorm(1150, 1083, 194, lower.tail = FALSE)
#&gt; [1] 0.3649116</code></pre>
<p>So there is about 36% chance of picking a student with a score of 1150 or more. Now let’s ask the opposite question.</p>
<p><strong>What range of scores cover 95% of the population?</strong></p>
<p>In order to cover 95% of the population, we have to leave 2.5% area on either side of the curve. This means we have to compute 2 quantiles given two probabilities - .025 and .975</p>
<pre class="r white"><code>qnorm(c(.025, .975), 1083, 194)
#&gt; [1]  702.767 1463.233</code></pre>
<p>Now let’s apply the same calculation to our 4-cylinder data:</p>
<pre class="r white"><code>signif(qnorm(c(.025, .975), 28.8, semean_hwy_4), 3)
#&gt; [1] 27.8 29.8</code></pre>
<p>This is pretty close to the calculation we did earlier using the fact the 95% of the range is covered by approximately 2 standard deviations around the mean.</p>
</div>
<div id="hypothesis-testing---a-systematic-approach-to-compare-sample-data" class="section level3">
<h3>Hypothesis Testing - A Systematic Approach to Compare Sample Data</h3>
<p><strong>Simpler case - given a population mean and a sample data</strong></p>
<p><em>Question: Did the sample came from the same population?</em></p>
<p>In this situation, a population is known and we want to compare our sample and infer if the sample came from the same population or a different one. Let’s assume for the sake of argument here that population mean for all 4 cylinder cars is 27 mpg. The question is how likely is that our sample came from this population. This and similar type if questions can be tested more systematically using <em>hypthesis testing</em> framework. The basic idea is we create two hypotheses:</p>
<ul>
<li><strong>Null Hypothesis (Ho)</strong>: The sample came from same population. This is the status quo.</li>
<li><strong>Alternate Hypothesis (Ha)</strong>: The sample came from a different population.</li>
<li>Then we assume Ho to be true.</li>
<li>Then we look at the sample data and try to see if there is <em>enough evidence to reject Ho</em>. We do this by calulating probabilty of getting the mean as or more extreme as we did in our sample.</li>
<li>If the probability is less than a certain threshold value, we say that it is unlikely to get a mean as or more extreme as we did in our sample and thus reject the null hypothesis.</li>
<li>If the probability is not less than the threshold we chose, then we say we <em>fail to reject null</em>.</li>
</ul>
<p>In our fuel economy sample, Ho is that population mean from which the sample is drawn is 27 mpg. Ha is that the population mean from which sample is drawn is <em>not</em> 27 mpg. Let’s find the probability of obtaining a mean as extreme or more than 28.8 mpg given that population mean is 27 mpg.</p>
<pre class="r white"><code>2 * pnorm(28.8, 27, semean_hwy_4, lower.tail = FALSE)
#&gt; [1] 0.0003362302</code></pre>
<p>We multiplied by 2 to calculate <em>two-sided</em> probability since Ha that we are evaluating states <em>not equal</em> to 27 mpg. If Ha was defined to be <em>more</em> or <em>less</em> than 27 mpg, then we would have used <em>one-sided</em> probability. So there is 0.03% chance that we would observe the mean that we did assuming Ho to be true. A typical threshold is 5%, considering which we reject the null and say that the sample is extremely unlikely to have come from the population with a mean of 27 mpg.</p>
<p><strong>What is a <em>p-value</em> ?</strong></p>
<p>What we just computed above (.03%) is called a p-value. The threshold is called <em>alpha</em>. In these terms, we reject Ho if p-value is less than alpha and fail to reject if it is equal to or greater than alpha. Can I ever run into a situation where I incorrectly reject (or fail to reject) Ho? We are never 100% certain of our conclusions so, yes, you can!</p>
</div>
<div id="potholes-in-hypothesis-testing" class="section level3">
<h3>Potholes in Hypothesis Testing</h3>
<p>Now what if my p-value is less than 0.05 and I reject Ho but in reality Ho was true? In that case, we made an error which in statistical circles is commonly known as <strong>Type 1 Error</strong>. This can happen because we always choose a non-zero value of alpha, which controls the Type 1 error rate. Alpha = 0.05 means that there will be about 5% cases where I will incorrectly reject Ho.</p>
<p>Since I want to keep Type 1 error as small as possible, I want to keep the value of alpha as small as I can. What is the smallest I can go on alpha? Theoretically, you can go as low as 0 giving you a Type 1 error rate of 0. But this would lead to a problem. Since p-value is the probability and thus cannot go negative, we will never reject Ho in this case, no matter how far my observed mean is from Ho! Now we will run into another problem when Ha is true and we are committing another error known as <strong>Type 2 Error</strong> - the probability of failing to reject Ho when in fact Ho is false.</p>
<p>Ideally, we want to minimize both Type 1 and 2 errors. Type 2 error is called <em>Beta</em>. But we ususally don’t think in terms of Beta. Instead we think in terms of <em>Power</em>.</p>
</div>
<div id="what-is-power" class="section level3">
<h3>What is Power?</h3>
<p><em>Power</em> is the probability of rejecting Ho when it is false. This is <em>1 - Beta</em>. To calculate power we need to know what the distribution under Ha looks like. Now this is sort of ‘hypothetical problem’ (this is because Ha is not defined precisely, but rather in terms of inequality). Recall that Ha is stated as <em>less than/not equal to/greater than</em> so we don’t know what the mean is under Ha.</p>
<p><img src="../images/power_hypothesis.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Power instead is used to design experiments. We first ask ourselves, what effect size do we want to measure? For example, average price of books from one seller is $50.00 and we want to compare if another seller has a price difference of $0.50, $1.00 or $5.00. This results in an interplay between:</p>
<ul>
<li><strong>Effect size</strong>: The larger the size, the more power you have (easier to identify the effect)</li>
<li><strong>Sample size</strong>: Recall that SE of mean is inversally proportional to square root of sample size. So larger the sample size, more squeezed will be the distribution of means towards the center. This will result in less overlap between Ho and Ha distribution (for the same effect size) and thus more power.</li>
<li><strong>Alpha</strong>: Since power is the probability of rejecting Ho when it is false, it is the area under the Ha curve beyond the alpha value. So as we decrease alpha (in an effort to reduce type 1 error rate), we also decrease the area under Ha, thus decreasing the power.</li>
</ul>
<p>We will perform these calculations assuming <em>t-distribution</em> which is discussed next.</p>
</div>
<div id="small-sample" class="section level3">
<h3>Small Sample?</h3>
<p>So far we have been assuming that our sample size is reasonably large (typically greater than 30) for CLT to be valid. We may come across problems where sample size is not sufficiently large. In those cases, we simply switch from assuming a normal distribution for our data to assuming a <strong>Student t Distribution</strong>. <em>t-distribution</em> takes only one parameter, <em>degrees of freedom</em> (n-1) and we replace our <em>pnorm</em> and <em>qnorm</em> functions with <code>pt</code> and <code>qt</code> for calculating the probabilities and quantiles.</p>
<pre class="r white"><code>CI_4_t &lt;- mean(pull(hwy_4)) + qt(c(.025, .975), 80) * semean_hwy_4
CI_4_t
#&gt; [1] 27.80346 29.80148</code></pre>
<p>Note that there is no direct function to input mean and se inside <em>qt</em> function so we first calculate the vector of relevant quantiles from <em>df</em>, then multiply it by SE of estimate and then add this to the mean of the sample. Also note that in this particular case, sample size is fairly large, and thus the confidence interval predicted by t-distribution is pretty close to those computed from the normal distribution assumption.</p>
<p>Since t-distribution works well for both small and large samples, a general rule of thumb is to assume t-distribution instead of normal. Let’s try to layout the steps and methods to solve different types of problems using the t-distrubution.</p>
</div>
<div id="problems" class="section level3">
<h3>Problems</h3>
<p>Here we identify typical questions/problems, go through the steps needed to solve the problem and finally use <code>t.test</code> function for a more compact form of our solution method.</p>
<p><strong>Given a vector of random numbers (also called a <em>single sample</em>), what is the 95% confidence interval for mean?</strong></p>
<p><em>Using systematic calculation steps</em></p>
<ul>
<li>Step 1: Compute sample mean</li>
<li>Step 2: Compute sample standard deviation</li>
<li>Step 3: Compute standard error of mean</li>
<li>Step 4: Compute degrees of freedom</li>
<li>Step 5: Compute t-statistic</li>
<li>Step 6: Compute confidence interval</li>
<li>Step 7: State your finding</li>
</ul>
<p>Let’s apply this method to our 4-cylinder data:</p>
<pre class="r white"><code>hwy_4 &lt;- pull(hwy_4)    # convert tibble to vector
s_mean &lt;- mean(hwy_4)
s_sd &lt;- sd(hwy_4)
se_mean_4 &lt;- s_sd / sqrt(length(hwy_4))
df_4 &lt;- length(hwy_4) - 1
ts_4 &lt;- qt(0.025, df_4)
ci_4 &lt;- s_mean + c(1, -1) * ts_4 * se_mean_4
ci_4
#&gt; [1] 27.80411 29.80082</code></pre>
<p><em>Using <code>t.test</code></em></p>
<p>Since the output of a single sample <code>t.test</code> includes confidence interval, we can directly use that:</p>
<pre class="r white"><code>t.test(hwy_4)
#&gt; 
#&gt;  One Sample t-test
#&gt; 
#&gt; data:  hwy_4
#&gt; t = 57.413, df = 80, p-value &lt; 2.2e-16
#&gt; alternative hypothesis: true mean is not equal to 0
#&gt; 95 percent confidence interval:
#&gt;  27.80411 29.80082
#&gt; sample estimates:
#&gt; mean of x 
#&gt;  28.80247</code></pre>
<p>And if we just want confidence interval, we can exract that with <strong>conf.int</strong>:</p>
<pre class="r white"><code>t.test(hwy_4)$conf.int
#&gt; [1] 27.80411 29.80082
#&gt; attr(,&quot;conf.level&quot;)
#&gt; [1] 0.95</code></pre>
<p><em>Conclusion</em>: We are 95% confident that our sample mean lies between 27.8 and 29.8 mpg.</p>
<p><strong>Given a random vector, what is the chance that it came from a population with mean muo?</strong></p>
<p><em>Using systematic calculation steps</em></p>
<ul>
<li>Step 1: Define hypothesis: Ho: mean = muo Ha: mean != muo</li>
<li>Step 2: Compute sample mean, sample standard deviation, standard error of mean and degrees of freedom</li>
<li>Step 3: Find T-Score = (sample mean - muo) / SEmean</li>
<li>Step 4: Find p-value
<ol style="list-style-type: lower-alpha">
<li>if T +ve, 2 * pt(T-score, df, lower.tail = FALSE)</li>
<li>if T -ve, 2 * pt(T-score, df)</li>
</ol></li>
<li>Step 5: Decide
<ol style="list-style-type: lower-alpha">
<li>if p-value &lt; alpha, reject Ho in favor of Ha</li>
<li>if p-value &gt; alpha, fail to reject Ho</li>
</ol></li>
</ul>
<p>Let’s apply this method to our 4-cylinder data using muo as 27 mpg:</p>
<pre class="r white"><code>T_score_4 &lt;- (s_mean - 27) / se_mean_4
T_score_4
#&gt; [1] 3.592938</code></pre>
<pre class="r white"><code>p_val_4 &lt;- 2 * pt(T_score_4, df_4, lower.tail = FALSE)
p_val_4
#&gt; [1] 0.0005631338</code></pre>
<p><em>Using <code>t.test</code></em></p>
<pre class="r white"><code>t.test(hwy_4 - 27)
#&gt; 
#&gt;  One Sample t-test
#&gt; 
#&gt; data:  hwy_4 - 27
#&gt; t = 3.5929, df = 80, p-value = 0.0005631
#&gt; alternative hypothesis: true mean is not equal to 0
#&gt; 95 percent confidence interval:
#&gt;  0.8041141 2.8008242
#&gt; sample estimates:
#&gt; mean of x 
#&gt;  1.802469</code></pre>
<p><em>Conclusion</em>: Since p-value is less than 0.05 (alpha), we reject Ho in favor of Ha concluding that there is significant difference between our sample and Ho mean of 27 mpg. Also note that in this case also results of our systematic steps match with p-value from t.test validating our steps.</p>
<p><strong>Given two samples, where the data from the two samples is <em>independant</em>, is there a statistical difference between the two?</strong></p>
<p>In this case the calculation of the confidence interval gets messy, even if variance between the two samples is assumed equal. It is even more complicated if you don’t assume that the variance is equal. That means you will solve a problem once and then easily forget it. Instead, <code>t.test</code> can rescue us again:</p>
<pre class="r white"><code>hwy_6 &lt;- pull(hwy_6)    # convert tibble to vector
t.test(hwy_4, hwy_6)
#&gt; 
#&gt;  Welch Two Sample t-test
#&gt; 
#&gt; data:  hwy_4 and hwy_6
#&gt; t = 9.1874, df = 153.28, p-value = 2.672e-16
#&gt; alternative hypothesis: true difference in means is not equal to 0
#&gt; 95 percent confidence interval:
#&gt;  4.693873 7.265496
#&gt; sample estimates:
#&gt; mean of x mean of y 
#&gt;  28.80247  22.82278</code></pre>
<p>By default, <em>t.test</em> assumes unequal variance. You can set <code>var.equal = TRUE</code> if needed.</p>
<p><em>Conclusion</em>: Since p-value is extremely small, we reject the null hypothesis and say that the two samples are not equal. In addition, we are 95% confident that the difference between means of the 4-cylinder vehicles and 6-cylinder vehicles is between 4.7 and 7.3 mpg.</p>
<p><strong>Given two samples where the data in the two samples is <em>paired</em>, is there a statistical difference between tht two?</strong></p>
<p>For this problem, let’s use <code>sleep</code> data available in R from Gosset’s Biometrika paper. It shows number of hours of sleep for 10 patients on two separate drugs.</p>
<pre class="r white"><code>data(sleep)
str(sleep)
#&gt; &#39;data.frame&#39;:    20 obs. of  3 variables:
#&gt;  $ extra: num  0.7 -1.6 -0.2 -1.2 -0.1 3.4 3.7 0.8 0 2 ...
#&gt;  $ group: Factor w/ 2 levels &quot;1&quot;,&quot;2&quot;: 1 1 1 1 1 1 1 1 1 1 ...
#&gt;  $ ID   : Factor w/ 10 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 2 3 4 5 6 7 8 9 10 ...</code></pre>
<pre class="r white"><code>group1 &lt;- sleep %&gt;%
    filter(group == 1) %&gt;%
    select(extra) %&gt;%
    pull()
group2 &lt;- sleep %&gt;%
    filter(group == 2) %&gt;%
    select(extra) %&gt;%
    pull()
t.test(group2, group1, paired = TRUE)
#&gt; 
#&gt;  Paired t-test
#&gt; 
#&gt; data:  group2 and group1
#&gt; t = 4.0621, df = 9, p-value = 0.002833
#&gt; alternative hypothesis: true difference in means is not equal to 0
#&gt; 95 percent confidence interval:
#&gt;  0.7001142 2.4598858
#&gt; sample estimates:
#&gt; mean of the differences 
#&gt;                    1.58</code></pre>
<p><em>Conclusion</em>: Since the 95% confidence interval does not include 0, we can say that there is a significant difference between the two drugs.</p>
<p><strong>The average fuel economy of a 4-cylinder car is 28 mpg. It is claimed that with the introduction of a new technology, the fuel economy increased to 29 mpg. How many observations should we take to study this claim to get a power of 80% from our test? Assume that the standard deviation in mean mpg is 0.5 mpg and we need 95% confidence interval.</strong></p>
<p>This can be answered using <code>power.t.test</code> function which will compute either power, sample size, change that we are interested in measuring or the standard deviation given the rest. Let’s use this to compute sample size in our case:</p>
<pre class="r white"><code>power.t.test(power = 0.8, delta = 1, sd = 0.5, alt = &quot;one.sided&quot;, type = &quot;one.sample&quot;)
#&gt; 
#&gt;      One-sample t test power calculation 
#&gt; 
#&gt;               n = 3.338489
#&gt;           delta = 1
#&gt;              sd = 0.5
#&gt;       sig.level = 0.05
#&gt;           power = 0.8
#&gt;     alternative = one.sided</code></pre>
<p>So I need 4 samples to distinguish this difference.</p>
<p><strong>What is the maximum difference I can detect at 80% power level with sample size of 50 and standard deviation of 1?</strong></p>
<pre class="r white"><code>power.t.test(power = 0.8, sd = 1, n = 50)
#&gt; 
#&gt;      Two-sample t test power calculation 
#&gt; 
#&gt;               n = 50
#&gt;           delta = 0.5658836
#&gt;              sd = 1
#&gt;       sig.level = 0.05
#&gt;           power = 0.8
#&gt;     alternative = two.sided
#&gt; 
#&gt; NOTE: n is number in *each* group</code></pre>
<p>So I can detect a maximum delta of 0.56.</p>
</div>
<div id="what-if-i-want-to-study-a-test-statistic-other-than-mean" class="section level3">
<h3>What if I Want to Study a Test Statistic Other than Mean?</h3>
<p>The confidence intervals that we have generated for our hypothesis testing has revolved around means where CLT has helped us a lot. But the CLT does not say anything about a different statistic, for example, median or variance. Sometimes I may be interested in looking at the differences in medians instead. How can I create a confidence interval of median and other statistics? Here, fundamentally we are saying what if my statistic does not follow a normal or a t-distribution. In this regard, it is also applicable to mean if there is a skew in its distribution (becaues assumptions of t-distribution are also violated in the presence of skew).</p>
<p>Here, the <em>bootstrap technique</em> (also known as <em>resampling technique</em>) will come to our rescue.</p>
<p><strong>How does it work?</strong></p>
<p>So we have one sample staring at us. What do we do? Imagine we put all those numbers in a sack. Then we randomly pick one number out, note it down, and <em>put it back</em> in the sack. We shuffle the contents of our sack and pick another number, note it down and put it back in the sack again. In statistical circles, this is called <em>sampling with replacement</em>. Note that in this experiment, we can get the same number again during our second pick. Now we can have virtually endless supply of numbers, which are coming from the sample, and thus represents the distribution of our sample. This way we can ‘create’ thousands of samples giving us thousands of any test statistic that we want. We then just need to look at the distribution of our test statistic to create confidence intervals.</p>
<p><strong>How do we do this in R?</strong></p>
<p>We will use <code>sample</code> function with <code>replace = TRUE</code> to generate the number of samples we want. We will then arrange the resulting vector into a matrix and use the <code>apply</code> function to compute our test statistic for all samples. Finally we employ <code>quantile</code> function to pick any quantile from our test statistic distribution. Let’s use this to calculate 95% CI for mean and then median for our 4-cylinder mpg data:</p>
<pre class="r white"><code>n &lt;- length(hwy_4)
N &lt;- 10000
resamps_hwy_4 &lt;- sample(hwy_4, n * N, replace = TRUE)
resamps_hwy_4_mat &lt;- matrix(resamps_hwy_4, N)
resamp_mean &lt;- apply(resamps_hwy_4_mat, 1, mean)
resamp_median &lt;- apply(resamps_hwy_4_mat, 1, median)
quantile(resamp_mean, c(0.025, 0.975))
#&gt;     2.5%    97.5% 
#&gt; 27.85185 29.81481</code></pre>
<pre class="r white"><code>quantile(resamp_median, c(0.025, 0.975))
#&gt;  2.5% 97.5% 
#&gt;    27    29</code></pre>
<p>Note that our 95% CI for mean agrees very well with our earlier calculations using CLT! But the best part is this is a general technique that can be applied to any statistic that we are interested in. Finally it is a good idea to look at the histogram of both:</p>
<pre class="r white"><code>resamp_mean %&gt;%
    as.tibble() %&gt;%
    ggplot(aes(value)) +
    histogram() +
    theme_simple()</code></pre>
<p><img src="/post/statistical-inference-using-R_files/figure-html/unnamed-chunk-24-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r white"><code>
resamp_median %&gt;%
    as.tibble() %&gt;%
    ggplot(aes(value)) +
    histogram() +
    theme_simple()</code></pre>
<p><img src="/post/statistical-inference-using-R_files/figure-html/unnamed-chunk-24-2.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="permutation-testing---a-different-way-of-hypothesis-testing" class="section level3">
<h3>Permutation Testing - A Different Way of Hypothesis Testing</h3>
<p>Permutation testing is a very interesting idea to test if two groups are different.</p>
<p><strong>How does it work?</strong></p>
<p>You start with the hypothesis that the two groups are same (come from the same population). In other words, this means that the ‘labels’ identifying the two groups are irrelevent. So we compute our test statistic from the original groups. Then we shuffle the labels to create a ‘second sample’ and calculate our test statistic again. This way we can continue to shuffle and recompute test statistic as many times as we want. This allows us to create a distribution. We can then use this distribution to find what proportion of our test statistic is as or more extreme than our original group. If this is less than a certain threshold, we reject the null hypotesis and say that the two groups are different.</p>
<p><strong>How do we do this in R?</strong></p>
</div>
